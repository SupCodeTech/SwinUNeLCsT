import os,math
import random
from time import time
import numpy as np
import torchnet as tnt
import torch
import torch.nn as nn
import torch.distributed as dist
from torch.utils.data import DistributedSampler
from torch.nn.parallel import DistributedDataParallel
import torch.optim as optim
import torch.nn.functional as F
import torchvision.utils as vutils
import torchvision.models as models
import torch.backends.cudnn as cudnn
import torch.cuda.amp as amp
from torch.utils import data
from datetime import datetime
from tqdm import tqdm
import socket
import argparse
import basic_function as func
#import dataset as CustomDataset
import dataset
import loss as loss
from sklearn.metrics import accuracy_score
from tensorboardX import SummaryWriter
from utils import get_dataloader,get_model

parser = argparse.ArgumentParser(description='PyTorch Hierachy_dif Training')
# model define
parser.add_argument('--layers', type=int, metavar='LAYERS',default= 50, help='the layer number of resnet: 18, 34, 50, 101, 152')
parser.add_argument('--numclasses', type=int, metavar='NUMCLASSES', default=21, help='number of classes')
parser.add_argument('--model_path', default= 'None' ,help='pretrain model path')
parser.add_argument('--model_type',default='deeplabv3p',help='Model type selection. deeplabv3p_lorm|deeplabv3p|deeplabv2')
parser.add_argument ('--shrink_factor', default=1, type=int, metavar='SHRINK',
                                   help='shrink factor of attention map, resevered for URSS paper.' )
# loss function
parser.add_argument('--l_segs',default=1,type=float,help='The loss weight of the segmentation loss')
parser.add_argument('--l_pesudo',default=0,type=float,help='The loss weight of the pesudo labels')
parser.add_argument('--l_lorm',default=0,type=float,help='The loss weight of local rectification module, must used with deeplabv3p_lorm')
parser.add_argument('--label_smooth',default=0,type=float,help='label smooth for pesudo labels generated by CAM methods. 0~0.9 use CE loss with label smoothing;')
parser.add_argument('--l_ds',default=0,type=float,help='0 or 1. Use distanceminentropy loss of scribble basing on distance map.')
parser.add_argument('--l_dc',default=0,type=float,help='0 or 1. Use distanceminentropy loss of CAM basing on distance map.')
# dataset
parser.add_argument('--dataset_path', metavar='DATASET_PATH',default='dataset/ScribbleSup', help='path to the dataset(multiple paths are concated by "+")')
parser.add_argument('--dataset', metavar='DATASET',default='SBD_pesudo_distancemap', help='dataset: VOC2012|PascalContext|SBD_pesudo|SBD_pesudo_disancemap|ScribbleOnly|scribble_pseudo_dsmp')
parser.add_argument('--train_path', metavar='TRAIN_PATH',default='pascal_2012_scribble', help='path to the dataset training file')
parser.add_argument('--pesudo_path',type=str,default='bmp_ws_train_aug_dataset')
parser.add_argument('--distancemap_s',default='distancemap/scribble/dsmp_lambd_e',help='The relative folder path of the scribble distance map pngs, ')
parser.add_argument('--distancemap_c',default='distancemap/cam/dsmp_lambd_e6',help='The path of the CAM distance map pngs')
# train paramters
parser.add_argument('--workers', default=4, type=int, metavar='WORKERS', help='number of dataload worker')
parser.add_argument('--batchsize', default=16, type=int, metavar='BATCH_SIZE', help='batchsize')
parser.add_argument('--epochs', default=50, type=int, metavar='EPOCH',help='number of total epochs to run')
parser.add_argument('--chk_interval',default=5,type=int,help='Save interval')
parser.add_argument('--val_epoch',default=0,type=int,help='Do not validate before this epoch, used when training on COCO2014 dataset ')
# optimizer
parser.add_argument('--lr', default=1e-3, type=float, metavar='LEARNING_RATE', help='learning rate')
parser.add_argument('--warmup_epoch', default=5, type=float, metavar='LEARNING_RATE', help='learning rate')
parser.add_argument('--wdecay', default=5e-4, type=float, metavar='WEIGHT_DECAY', help='weight decay')
parser.add_argument('--momentum', default=0.9, type=float, metavar='MOMENTUM', help='the momentum of SGD learning algorithm')

# distributed training
parser.add_argument('--distributed',default=False,type=bool,help='Use torch.distributed')
parser.add_argument('--local_rank',default=-1,type=int,help='Node rank for distributed training')
parser.add_argument('--device',default='cuda',type=str)
parser.add_argument('--logdir', default='./log/', type=str,
                        help='path where to save, empty for no saving')

args = parser.parse_args()

class Trainer():
    def __init__(self, args):
        self.args = args
        self.date = datetime.now().strftime('%b%d_%H-%M-%S')+'_'+socket.gethostname()
        self.best_pred = 0
        
        
        value_scale = 255
        mean = [0.485, 0.456, 0.406]
        mean = [item * value_scale for item in mean]
        std = [0.229, 0.224, 0.225]
        std = [item * value_scale for item in std]

        self.train_loader, self.val_loader = get_dataloader(args,args.distributed)
        self.model = get_model(args.model_type,args.distributed,args,local_rank,device)
        
        # learning rate and optimizer
        self.warmup_epoch = args.warmup_epoch
        self.max_step = args.epochs * len(self.train_loader)
        self.base_lr = args.lr # 1e-3
        if args.distributed:
            self.base_lr = world_size*self.base_lr # n * 1e-3 
            self.lr = self.base_lr
            print('Effective lr : ',self.base_lr)

        else:
            self.lr = args.lr

        self.optimizer = optim.SGD(filter(lambda p: p.requires_grad, self.model.parameters()),lr=self.lr, momentum=args.momentum, weight_decay=args.wdecay)
        # self.scheduler = torch.optim.lr_scheduler.LambdaLR(self.optimizer, lr_lambda=lambda step: 10 * ((1.0-float(step)/self.max_step)**0.9))

        # loss functions
        self.criterion_CE = loss.SegLoss(255)
        if args.label_smooth > 0:
            self.pesudolabel_entropy = nn.CrossEntropyLoss(ignore_index=255,label_smoothing=args.label_smooth)


        if args.l_ds >0 or args.l_dc>0:
            self.distanceMap_entropy_loss = loss.DistanceMapMinEntropy(numclass=args.numclasses)
        else:
            self.distanceMap_entropy_loss = None
        
        
        # imagenet pretrained model
        resnet = models.__dict__['resnet' + str(args.layers)](weights="ResNet"+str(args.layers)+"_Weights.IMAGENET1K_V1")
        if args.model_path != 'None':
            model_resnet = torch.load(args.model_path)
            self.model = func.param_restore_all(self.model, model_resnet['state_dict'])
        else:
            if args.distributed:
                self.model= func.param_restore(self.model.module, resnet.state_dict())
            else:
                self.model= func.param_restore(self.model, resnet.state_dict())
    def train(self, epoch):
        scaler = amp.GradScaler()
        self.model.train()
        losses = func.AverageMeter()
        tbar = tqdm(self.train_loader,position=local_rank,ncols=95)
        for i, batch in enumerate(tbar):
            # cur_lr = self.scheduler.get_last_lr()[0]
            # if i >50:
            #     break
            self.lr = self.adjust_learning_rate(self.optimizer,epoch*len(tbar)+i,self.max_step,0,self.base_lr,warmup_step=self.warmup_epoch*len(tbar))
            cur_lr = self.lr
            if args.dataset == 'ScribbleOnly': # only scribbles are used
                img, label_scribble, path_name = batch
                img_v = img.to(device)
                label_scribble_v = label_scribble.to(device)
                batch_size = img.size()[0]
                input_size = img.size()[2:4]
            elif args.dataset == 'PseudoOnly': # 
                img,label_scribble,label_pesudo,path_name = batch
                img_v = img.to(device)
                label_scribble_v = label_scribble.to(device)
                label_pesudo_v = label_pesudo.to(device)
                batch_size = img.size()[0]
                input_size = img.size()[2:4]
            elif args.dataset == 'ScribblePseudo':
                img,label_scribble,label_pesudo,path_name = batch
                img_v = img.to(device)
                label_scribble_v = label_scribble.to(device)
                label_pesudo_v = label_pesudo.to(device)
                batch_size = img.size()[0]
                input_size = img.size()[2:4]
            elif args.dataset == 'ScribblePseudoDsDc':
                img,label_scribble,label_pesudo,distancemap_s,distancemap_c,path_name = batch
                img_v = img.to(device,non_blocking=True)
                label_scribble_v = label_scribble.to(device,non_blocking=True)
                label_pesudo_v = label_pesudo.to(device,non_blocking=True) # b,h,w
                distancemap_s_v = distancemap_s.to(device,non_blocking=True) # b,h,w
                distancemap_c_v = distancemap_c.to(device,non_blocking=True) # b,h,w
                batch_size = img.size()[0]
                input_size = img.size()[2:4]
            elif args.dataset == 'scribble_pseudo_dsmp':
                img,label_scribble,label_pesudo,distancemap_s,path_name = batch
                img_v = img.to(device,non_blocking=True)
                label_scribble_v = label_scribble.to(device,non_blocking=True)
                label_pesudo_v = label_pesudo.to(device,non_blocking=True) # b,h,w
                distancemap_s_v = distancemap_s.to(device,non_blocking=True) # b,h,w
                batch_size = img.size()[0]
                input_size = img.size()[2:4]
            
            with amp.autocast():
                if args.model_type == 'deeplabv3p':
                    pred_seg = self.model(img_v)
                elif args.model_type == 'deeplabv2':
                    pred_seg = self.model(img_v)
                elif args.model_type == 'deeplabv3p_lorm':
                    pred_seg,lorm_loss = self.model(img_v,label_scribble_v,label_pesudo_v)
                else:
                    pred_seg,_ = self.model(img_v)# pred_class: (2,20) pred_seg: 8,21,59,59                    
                pred_sg_up = F.interpolate(pred_seg, size=input_size, mode='bilinear', align_corners=True)
                if torch.min(label_scribble_v[label_scribble_v.ne(255)]) <0 or torch.max(label_scribble_v[label_scribble_v.ne(255)]) >=args.numclasses:
                    print('label_scribble_v',path_name,torch.unique(label_scribble_v[label_scribble_v.ne(255)]))
                    
                loss_seg = self.criterion_CE(pred_sg_up, label_scribble_v.squeeze(1))
                loss = args.l_segs * loss_seg
                    
                if args.label_smooth >0:
                    loss_pesudolabel = self.pesudolabel_entropy(pred_sg_up,label_pesudo_v)
                    if torch.min(label_pesudo_v[label_pesudo_v.ne(255)]) <0 or torch.max(label_pesudo_v[label_pesudo_v.ne(255)]) >=args.numclasses:
                        print('label_pesudo_v',path_name,torch.unique(label_pesudo_v[label_pesudo_v.ne(255)]))
                    if local_rank == 0:
                        writer.add_scalar('train/pesudolabel_loss',float(loss_pesudolabel),epoch*len(tbar)+i)
                    loss = loss + args.l_segc* loss_pesudolabel
                elif args.label_smooth == -1: # use distance to soft the CAM label. Abandoned. do not activate this.
                    label_pesudo_v[label_pesudo_v==255] = 0
                    loss_pesudolabel = self.pesudolabel_entropy(pred_sg_up,label_pesudo_v,distancemap_s_v)
                    if local_rank == 0:
                        writer.add_scalar('train/pesudolabel_loss',float(loss_pesudolabel),epoch*len(tbar)+i)
                    loss = loss + args.l_segc*loss_pesudolabel
                    
                if args.l_ds > 0:
                    loss_l_ds =  self.distanceMap_entropy_loss(pred_sg_up,distancemap_s_v)
                    if local_rank == 0:
                        writer.add_scalar('train/l_ds',float(loss_l_ds),epoch*len(tbar)+i)
                    loss = loss + args.l_ds * loss_l_ds
                if args.l_dc > 0:
                    loss_l_dc =  self.distanceMap_entropy_loss(pred_sg_up,distancemap_c_v)
                    if local_rank == 0:
                        writer.add_scalar('train/l_dc',float(loss_l_dc),epoch*len(tbar)+i)
                    loss = loss + args.l_dc * loss_l_dc
                if args.l_lorm > 0:
                    lorm_loss = args.l_lorm*lorm_loss
                    if local_rank == 0:
                        writer.add_scalar('train/labelFusino_entropy',float(lorm_loss),epoch*len(tbar)+i)
                    loss = loss + lorm_loss
                
                
                # print(loss)
                self.optimizer.zero_grad()
                scaler.scale(loss).backward()
                scaler.step(self.optimizer)
                scaler.update()
            losses.update(loss.item(), img.size(0))
            
            tbar.set_description('Train [{0}|{1}] Loss {loss.val:.3f} {loss.avg:.3f} Lr {lr:.5f} Best {best:.4f}'.format(local_rank,epoch, loss=losses, lr=cur_lr, best=self.best_pred))
            if local_rank == 0:
                writer.add_scalar('train/train_lr',float(cur_lr),epoch*len(tbar)+i)
                writer.add_scalar('train/seg_loss',float(loss_seg),epoch*len(tbar)+i)


        # self.scheduler.step()
        if args.local_rank == 0:
            writer.add_scalar('train/epoch_loss',losses.avg,epoch)


    def validate_tnt(self, epoch):
        confusion_meter = tnt.meter.ConfusionMeter(self.args.numclasses, normalized=False)
        losses = func.AverageMeter()
        tbar = tqdm(self.val_loader,position=local_rank,total=len(self.val_loader),ncols=90)
        self.model.eval()
        acc = 0
        with torch.no_grad():
            for i, batch in enumerate(tbar):
                # if i >50:
                #     break
                img, label_scribble,path_name = batch

                batch_size = img.size()[0]
                input_size = img.size()[2:4]

                img_v = img.to(device)
                label_scribble_v = label_scribble.to(device)

                # pred_seg,pred_class = self.model(img_v)
                # with amp.autocast():
                if args.model_type == 'deeplabv3p_lorm':
                    pred_seg = self.model.forward_eval(img_v)
                elif args.model_type == 'deeplabv3p':
                    pred_seg = self.model.forward_eval(img_v)
                elif args.model_type == 'deeplabv2':
                    pred_seg = self.model.forward(img_v)
                else:
                    pred_seg,_= self.model.forward(img_v)
                if args.distributed:
                    batch_img = [torch.zeros_like(img_v) for _ in range(world_size)]
                    batch_label_scribble = [torch.zeros_like(label_scribble_v) for _ in range(world_size)]
                    batch_pred_seg = [torch.zeros_like(pred_seg) for _ in range(world_size)]
                    dist.all_gather(batch_img,img_v)
                    dist.all_gather(batch_label_scribble,label_scribble_v)
                    dist.all_gather(batch_pred_seg,pred_seg)
                    img_v = torch.cat(batch_img,dim=0)
                    label_scribble_v = torch.cat(batch_label_scribble,dim=0)
                    pred_seg = torch.cat(batch_pred_seg,dim=0)

                pred_sg_up = F.interpolate(pred_seg, size=input_size, mode='bilinear', align_corners=True)
                loss = self.criterion_CE(pred_sg_up, label_scribble_v.squeeze(1))
                                
                label_scribble_v = label_scribble_v.cpu()
                valid_pixel = label_scribble_v.ne(255)
                pred_sg_up_label = torch.max(pred_sg_up, 1, keepdim=True)[1]
                pred_sg_up_label=torch.squeeze(pred_sg_up_label,1).cpu()
                
                confusion_meter.add(pred_sg_up_label[valid_pixel], label_scribble_v[valid_pixel])
                losses.update(loss.item(), img.size(0))
                tbar.set_description('Valid [{0}] Loss {loss.val:.3f} {loss.avg:.3f} Rank={rank}'.format(epoch, loss=losses,rank=local_rank))
                # for tensorboard
                if i == 0 and local_rank == 0:
                    colormap = func.vocpallete
                    cp=torch.from_numpy(np.array(colormap)).reshape((-1,3)).float()
                    pred_seg=cp[pred_sg_up_label,:].squeeze().permute(0,3,1,2)
                    pred_seg = pred_seg[0:batch_size] # because we have gathered from dist, so we just need to pick the former batchsize ones.
                    label=cp[label_scribble_v.cpu(),:].squeeze().permute(0,3,1,2)
                    label = label[0:batch_size]
                    img_vis = img_v[0:batch_size].cpu().clone() ########### this for debug
                    value_scale = 255
                    mean = [0.485, 0.456, 0.406]
                    mean = torch.tensor([item * value_scale for item in mean]) # [3]
                    std = [0.229, 0.224, 0.225]
                    std = torch.tensor([item * value_scale for item in std])
                    mean = mean.unsqueeze(1).unsqueeze(1).unsqueeze(0).repeat(batch_size,1,input_size[0],input_size[1]) # [3] -> [3,256,256]
                    std = std.unsqueeze(1).unsqueeze(1).unsqueeze(0).repeat(batch_size,1,input_size[0],input_size[1])
                    img_vis = ((img_vis*std+mean)*255).to(torch.int32)
                    imgshow = torch.cat((label,pred_seg,img_vis),0)
                    img_grid = vutils.make_grid(imgshow,nrow=batch_size)
                    writer.add_image('label_scribble&pred_seg',img_grid,epoch)

            confusion_matrix = confusion_meter.value()
            inter = np.diag(confusion_matrix)
            union = confusion_matrix.sum(1).clip(min=1e-12) + confusion_matrix.sum(0).clip(min=1e-12) - inter

        mean_iou_ind = inter/union
        mean_iou_all = mean_iou_ind.mean()
        mean_acc_pix = float(inter.sum())/float(confusion_matrix.sum())
        if local_rank == 0:
            print(' * IOU_All {iou}'.format(iou=mean_iou_all)) # IOU ALL是平均IOU
            print(' * IOU_Ind {iou}'.format(iou=mean_iou_ind)) # IOU Ind是21个class的IoU
            print(' * ACC_Pix {acc}'.format(acc=mean_acc_pix))
            writer.add_scalar('val/val_loss',losses.avg,epoch)
            writer.add_scalar('val/val_iou',mean_iou_all,epoch)

        return mean_iou_all, mean_iou_ind, mean_acc_pix
    
 
    def adjust_learning_rate(self,optimizer, current_epoch, max_epoch, lr_min=0, lr_max=0.1, warmup_step=5):
        warmup_epoch = warmup_step
        if current_epoch < warmup_epoch:
            lr = lr_max * current_epoch / warmup_epoch
        elif current_epoch < max_epoch:
            lr = lr_min + (lr_max - lr_min) * (
                        1 + math.cos(math.pi * (current_epoch - warmup_epoch) / (max_epoch - warmup_epoch))) / 2
        else:
            lr = lr_min + (lr_max - lr_min) * (
                    1 + math.cos(math.pi * (current_epoch-max_epoch) / (max_epoch))) / 2
        for param_group in optimizer.param_groups:
            param_group['lr'] = lr
        return lr


if __name__ == '__main__':
    opt_manualSeed = 1000
    print("Random Seed: ", opt_manualSeed)
    np.random.seed(opt_manualSeed)
    random.seed(opt_manualSeed)
    torch.manual_seed(opt_manualSeed)
    torch.cuda.manual_seed_all(opt_manualSeed)

    #cudnn.enabled = True
    cudnn.benchmark = True
    cudnn.deterministic = False
    # os.environ["CUDA_VISIBLE_DEVICES"] = args.gpus
    # os.environ['CUDA_LAUNCH_BLOCKING'] = '1'

    device = torch.device(args.device)
    local_rank = 0
    world_size = 1
    if args.distributed:
        dist.init_process_group(backend='nccl')
        local_rank = dist.get_rank()
        torch.cuda.set_device(local_rank)
        device = torch.device('cuda', local_rank)
        world_size = dist.get_world_size()

    trainer = Trainer(args)
    # trainer.validate_tnt(0)
    if local_rank == 0:
        writer = SummaryWriter(os.path.join(args.logdir,trainer.date))
        log_path = os.path.join(args.logdir,trainer.date,'log.txt')
        f = open(log_path,'a')
        f.writelines(str(args)+'\n')
        f.close()
        print(str(args))

    iou_all, iou_ind, acc_pix = 0,0,0

    for epoch in range(args.epochs):
        # train and validate
        t1 = time()
        trainer.train(epoch)

        if epoch >= args.val_epoch:
            iou_all, iou_ind, acc_pix = trainer.validate_tnt(epoch)

        # save checkpoint
        is_best = (iou_all >= trainer.best_pred)
        trainer.best_pred = iou_all if is_best else trainer.best_pred
        # if local_rank == 0:
        #     func.save_checkpoint({
        #         'epoch': epoch,
        #         'state_dict': trainer.model.state_dict(),
        #         'best_pred': (iou_all, iou_ind, acc_pix, acc_class),
        #         'optimizer': trainer.optimizer.state_dict(),
        #     }, os.path.join(args.logdir,trainer.date), is_best)
        t2 = time()
        if local_rank == 0:
            state = {
                'epoch': epoch,
                'state_dict': trainer.model.state_dict(),
                'best_pred': (iou_all, iou_ind, acc_pix),
                'optimizer': trainer.optimizer.state_dict(),
            }
            if epoch % args.chk_interval == 0 or epoch == args.epochs-1:
                save_path = os.path.join(args.logdir,trainer.date,'checkpoint_%d.pth'%(epoch))
                torch.save(state,save_path)
            if is_best:
                save_path = os.path.join(args.logdir,trainer.date,'model_best.pth')
                torch.save(state,save_path)
            if epoch == args.epochs-1:
                save_path = os.path.join(args.logdir,trainer.date,'last_checkpoint.pth')
                torch.save(state,save_path)
            log_context = 'Epoch[%02d], iou_all[%.6f], time[%s]s\n' % (epoch,iou_all,(t2-t1))
            f = open(log_path,'a')
            f.writelines(log_context)
            f.close()

    if local_rank == 0:
        writer.close()
